{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nav_menu": {
      "height": "309px",
      "width": "468px"
    },
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Furg - ECD 06a - Machine Learning I - Árvores de decisão",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atejap05/pos_data_science_furg/blob/main/disciplinas/Machine_Learning_I/semana06/Furg_ECD_06a_Machine_Learning_I_%C3%81rvores_de_decis%C3%A3o.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwgRK9JZWmrB"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning I - Árvores de decisão\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "Código adaptado de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRq6T_0YWmrY"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_:\n",
        "\n",
        "- NumPy: suporte a vetores, matrizes e operações de Álgebra Linear\n",
        "- Matplotlib: biblioteca de visualização de dados\n",
        "- Scikit-Learn: biblioteca com algoritmos de Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEPzGx7xWmra"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sa1e6WbWmrd"
      },
      "source": [
        "Este notebook também utiliza a ferramenta Graphviz para visualizar as árvores de decisão. \n",
        "\n",
        "O pacote Graphviz já faz parte do ambiente Colaboratory.\n",
        "\n",
        "**Atenção:** para quem utiliza o ambiente Jupyter, é preciso primeiro instalar os pacotes `graphviz` e `python-graphviz`. Na linha de comando isso pode ser feito assim:\n",
        "\n",
        "    conda install graphviz python-graphviz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2NNEKXuWmrf"
      },
      "source": [
        "import graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EM-YLUkWmrg"
      },
      "source": [
        "# Classificação usando árvores de decisão\n",
        "\n",
        "**Árvores de decisão** (_decision trees_) é um algoritmo clássico de Machine Learning.\n",
        "\n",
        "Esta é uma técnica bastante versátil, podendo ser usada tanto para tarefas de classificação (que veremos a seguir) como de regressão (mais adiante neste _notebook_).\n",
        "\n",
        "Como exemplo usaremos novamente o conjunto de dados IRIS, interno à biblioteca `Scikit-Learn`. É o mesmo _dataset_ sobre características de três espécies de flores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ql3of0mWmrh"
      },
      "source": [
        "# importação dos dados\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data[:, 2:] # comprimento e largura da pétala\n",
        "y = iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkUYda7HWmri"
      },
      "source": [
        "# criação e treinamento do classificador\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree_clf = DecisionTreeClassifier(random_state=42, max_depth=2)\n",
        "tree_clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcQfc-4qWmrl"
      },
      "source": [
        "# visualização da árvore de decisão\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "vis = export_graphviz(tree_clf, feature_names=['comprimento', 'largura'], class_names=iris.target_names,\n",
        "                      rounded=True, filled=True, proportion=True)\n",
        "\n",
        "# exibição da figura\n",
        "graphviz.Source(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB1XiIAZWmrn"
      },
      "source": [
        "Suponha que você encontre uma flor de íris e queira classificá-la. Você começa no nodo raiz (profundidade 0, no topo). Este nodo pergunta se o comprimento da pétala da flor é menor ou igual a 2,45 cm. Se for, então você desce para o filho esquerdo da raiz (profundidade 1). Neste caso, é um nodo sem filhos, por isso não se faz mais nenhuma pergunta: a classe prevista para esse nodo é _Iris setosa_.\n",
        "\n",
        "Agora, suponha que você encontre outra flor, mas desta vez o comprimento da pétala é maior que 2,45 cm. Você deve descer até o filho direito da raiz (profundidade 1), que tem filhos. Então você faz outra pergunta: a largura da pétala é menor ou igual a 1,75 cm? Se for, então sua flor é provavelmente uma _Iris versicolor_ (profundidade 2, à esquerda). Se não, provavelmente é uma _Iris virginica_ (profundidade 2, à direita).\n",
        "\n",
        "É interessante notar que o algoritmo de àrvores de decisão não depende de preprocessamento. Em particular, não é necessário o escalonamento dos atributos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-827vgchWmro"
      },
      "source": [
        "A medida **samples** indica o percentual de todas as instâncias que o nodo representa.\n",
        "\n",
        "A medida **value** mostra as probabilidades de classificação para este nodo, em relação a todas as classes do problema.\n",
        "\n",
        "A medida **gini** mede a **impureza** de um nodo. Um nodo é dito **puro** (gini = 0) se todas as instâncias de treinamento a que este nodo se aplica pertencem à mesma classe.\n",
        "\n",
        "Não se preocupe com os detalhes do código abaixo, ele apenas mostra as fronteiras de decisão estabelecidas por esta árvore de decisão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPPKo5_tWmrs"
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_boundary(clf, X, y, axes=[0, 7.5, 0, 3], iris=True, legend=False, plot_training=True):\n",
        "    x1s = np.linspace(axes[0], axes[1], 100)\n",
        "    x2s = np.linspace(axes[2], axes[3], 100)\n",
        "    x1, x2 = np.meshgrid(x1s, x2s)\n",
        "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
        "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
        "    cmap1 = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=cmap1)\n",
        "    if not iris:\n",
        "        cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
        "        plt.contour(x1, x2, y_pred, cmap=cmap2, alpha=0.8)\n",
        "    if plot_training:\n",
        "        plt.plot(X[:, 0][y==0], X[:, 1][y==0], 'yo', label='Iris setosa')\n",
        "        plt.plot(X[:, 0][y==1], X[:, 1][y==1], 'bs', label='Iris versicolor')\n",
        "        plt.plot(X[:, 0][y==2], X[:, 1][y==2], 'g^', label='Iris virginica')\n",
        "        plt.axis(axes)\n",
        "    if iris:\n",
        "        plt.xlabel('comprimento da pétala', fontsize=14)\n",
        "        plt.ylabel('largura da pétala', fontsize=14)\n",
        "    else:\n",
        "        plt.xlabel(r'$x_1$', fontsize=18)\n",
        "        plt.ylabel(r'$x_2$', fontsize=18, rotation=0)\n",
        "    if legend:\n",
        "        plt.legend(loc='lower right', fontsize=14)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_decision_boundary(tree_clf, X, y)\n",
        "plt.plot([2.45, 2.45], [0, 3], 'k-', linewidth=2)\n",
        "plt.plot([2.45, 7.5], [1.75, 1.75], 'k--', linewidth=2)\n",
        "plt.plot([4.95, 4.95], [0, 1.75], 'k:', linewidth=2)\n",
        "plt.plot([4.85, 4.85], [1.75, 3], 'k:', linewidth=2)\n",
        "plt.text(1.40, 1.0, 'profundidade 0', fontsize=15)\n",
        "plt.text(3.2, 1.80, 'profundidade 1', fontsize=13)\n",
        "plt.text(4.05, 0.5, 'profundidade 2', fontsize=11)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-srty3kWmrt"
      },
      "source": [
        "# Predição de probabilidades e de classe\n",
        "\n",
        "Aqui vamos definir uma única instância e obter tanto as probabilidades associadas a cada classe como a classe mais provável que ela seja."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_CPWY9lWmrv"
      },
      "source": [
        "flor = [[5, 1.5]] # comprimento e largura da pétala"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_0XxIJuWmrw"
      },
      "source": [
        "tree_clf.predict_proba(flor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qclp4DDiWmrx"
      },
      "source": [
        "tree_clf.predict(flor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRkPSX9XWmry"
      },
      "source": [
        "# Regularização de árvores de decisão\n",
        "\n",
        "Relembrando, **regularizar** significa ajustar o modelo para evitar tanto situações de _overfitting_ como de _underfitting_.\n",
        "\n",
        "Para uma árvore de decisão, alguns hiperparâmetros podem ser ajustados para controlar os graus de liberdade da técnica de ajuste do modelo. Os mais importantes são:\n",
        "\n",
        "- `max_depth`, que define a profundidade máxima da árvore de decisão.\n",
        "\n",
        "- `min_samples_leaf`, que controla a quantidade mínima de instâncias em cada nodo sem filhos, reduzindo a complexidade da árvore de decisão.\n",
        "\n",
        "Como orientaçao geral, aumentar os hiperparâmetros que começam com `min_` ou reduzir os hiperparâmetros que começam com `max_ ` têm o efeito limitar os graus de liberdade do modelo. Assim se reduz o risco de _overfitting_, mas se feito excesso, aumenta o risco de _underfitting_.\n",
        "\n",
        "A seguir é feita uma comparação simples, mostrando as fronteiras de decisão, para o conjunto de dados sintético chamado `moons` (gerado pela biblioteca Scikit-Learn).\n",
        "\n",
        "Experimente alterar os valores de `max_depth` (valor padrão `None`, sem limite de profundidade) e `min_samples_leaf` (valor padrão 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTcRb-iKWmry"
      },
      "source": [
        "from sklearn.datasets import make_moons\n",
        "\n",
        "Xm, ym = make_moons(n_samples=100, noise=0.25, random_state=53)\n",
        "\n",
        "deep_tree_clf1 = DecisionTreeClassifier(random_state=42, max_depth=7, min_samples_leaf=1)\n",
        "deep_tree_clf2 = DecisionTreeClassifier(random_state=42, max_depth=7, min_samples_leaf=4)\n",
        "\n",
        "deep_tree_clf1.fit(Xm, ym)\n",
        "deep_tree_clf2.fit(Xm, ym)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(10, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_decision_boundary(deep_tree_clf1, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n",
        "plt.title('modelo 1', fontsize=16)\n",
        "plt.sca(axes[1])\n",
        "plot_decision_boundary(deep_tree_clf2, Xm, ym, axes=[-1.5, 2.4, -1, 1.5], iris=False)\n",
        "plt.title('modelo 2', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_z3vvpxWmr0"
      },
      "source": [
        "# Árvores de regressão\n",
        "\n",
        "Árvores de decisão também pode ser usadas para problemas de regressão, usando o algoritmo `DecisionTreeRegressor`, como mostrado abaixo.\n",
        "\n",
        "Um conjunto de pontos baseado em uma curva de grau dois com ruído é gerado, e então é feito um ajuste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-OXESJeWmr0"
      },
      "source": [
        "# conjunto sintético de grau 2\n",
        "\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(200, 1)\n",
        "y = 4 * (X - 0.5) ** 2\n",
        "y = y + np.random.randn(200, 1) / 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgaQWUNDWmr1"
      },
      "source": [
        "# criação e treinamento de árvore de regressão\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
        "tree_reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSMvXm8GWmr1"
      },
      "source": [
        "# exemplo de predição\n",
        "tree_reg.predict([[1.0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJSEB5IlWmr2"
      },
      "source": [
        "O trecho a seguir ilustra as fronteiras de decisão induzidas por árvores de decisão de profundidades diferentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M10M6QNmWmr2"
      },
      "source": [
        "# função auxiliar de plotagem\n",
        "\n",
        "def plot_regression_predictions(tree_reg, X, y, axes=[0, 1, -0.2, 1], ylabel='$y$'):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500).reshape(-1, 1)\n",
        "    y_pred = tree_reg.predict(x1)\n",
        "    plt.axis(axes)\n",
        "    plt.xlabel('$x_1$', fontsize=18)\n",
        "    if ylabel:\n",
        "        plt.ylabel(ylabel, fontsize=18, rotation=0)\n",
        "    plt.plot(X, y, 'b.')\n",
        "    plt.plot(x1, y_pred, 'r.-', linewidth=2, label='pred')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW5ONJfZWmr3"
      },
      "source": [
        "# dois modelos de exemplo\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(random_state=42, max_depth=2)\n",
        "tree_reg2 = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
        "tree_reg1.fit(X, y)\n",
        "tree_reg2.fit(X, y)\n",
        "\n",
        "# não se preocupe com os detalhes deste código\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
        "plt.sca(axes[0])\n",
        "plot_regression_predictions(tree_reg1, X, y)\n",
        "for split, style in ((0.1973, 'k-'), (0.0917, 'k--'), (0.7718, 'k--')):\n",
        "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
        "plt.text(0.21, 0.65, 'profundidade 0', fontsize=15)\n",
        "plt.text(0.0, -0.1, 'prof. 1', fontsize=13)\n",
        "plt.text(0.8, -0.1, 'prof. 1', fontsize=13)\n",
        "plt.legend(loc='upper center', fontsize=18)\n",
        "plt.title('max_depth_leaf={}'.format(tree_reg1.max_depth), fontsize=14)\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plot_regression_predictions(tree_reg2, X, y, ylabel=None)\n",
        "for split, style in ((0.1973, 'k-'), (0.0917, 'k--'), (0.7718, 'k--')):\n",
        "    plt.plot([split, split], [-0.2, 1], style, linewidth=2)\n",
        "for split in (0.0458, 0.1298, 0.2873, 0.9040):\n",
        "    plt.plot([split, split], [-0.2, 1], 'k:', linewidth=1)\n",
        "plt.text(0.3, 0.5, 'prof. 2', fontsize=13)\n",
        "plt.title('max_depth_leaf={}'.format(tree_reg2.max_depth), fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwLbUxeLZhkq"
      },
      "source": [
        "Note que o critério de divisão para cada nodo é o **mse**, que é simplesmente o quadrado da medida RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ42vJsXWmr5"
      },
      "source": [
        "# visualização da árvore de decisão para o modelo 1\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "vis = export_graphviz(tree_reg1, feature_names=['x1'], rounded=True, filled=True, proportion=True)\n",
        "\n",
        "# exibição da figura\n",
        "graphviz.Source(vis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIaVwXjWWmr6"
      },
      "source": [
        "Para este conjunto de dados, se não limitarmos a profundidade da árvore de decisão teremos _overfitting_, que pode ser observado no lado esquerdo da figura abaixo.\n",
        "\n",
        "Para prevenir isso (sem ter que arbitrar uma profundidade máxima), podemos definir o hiperparâmetro `min_samples_leaf` como um valor maior (o padrão é apenas 1). O resultado é mostrado no lado direito da figura."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHfQfqVtWmr6"
      },
      "source": [
        "# dois modelos de exemplo\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg2 = DecisionTreeRegressor(random_state=42, min_samples_leaf=10)\n",
        "tree_reg1.fit(X, y)\n",
        "tree_reg2.fit(X, y)\n",
        "\n",
        "# não se preocupe com os detalhes deste código\n",
        "\n",
        "x1 = np.linspace(0, 1, 500).reshape(-1, 1)\n",
        "y_pred1 = tree_reg1.predict(x1)\n",
        "y_pred2 = tree_reg2.predict(x1)\n",
        "\n",
        "fig, axes = plt.subplots(ncols=2, figsize=(12, 4), sharey=True)\n",
        "\n",
        "plt.sca(axes[0])\n",
        "plt.plot(X, y, 'b.')\n",
        "plt.plot(x1, y_pred1, 'r.-', linewidth=2, label='pred')\n",
        "plt.axis([0, 1, -0.2, 1.1])\n",
        "plt.xlabel('$x_1$', fontsize=18)\n",
        "plt.ylabel('$y$', fontsize=18, rotation=0)\n",
        "plt.legend(loc='upper center', fontsize=18)\n",
        "plt.title('min_samples_leaf={}'.format(tree_reg1.min_samples_leaf), fontsize=14)\n",
        "\n",
        "plt.sca(axes[1])\n",
        "plt.plot(X, y, 'b.')\n",
        "plt.plot(x1, y_pred2, 'r.-', linewidth=2, label=r'$\\hat{y}$')\n",
        "plt.axis([0, 1, -0.2, 1.1])\n",
        "plt.xlabel('$x_1$', fontsize=18)\n",
        "plt.title('min_samples_leaf={}'.format(tree_reg2.min_samples_leaf), fontsize=14)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ-HL_rsuEhA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}