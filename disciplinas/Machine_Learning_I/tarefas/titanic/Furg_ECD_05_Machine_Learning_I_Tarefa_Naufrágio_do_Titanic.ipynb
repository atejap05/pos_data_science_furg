{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "Furg - ECD 05 - Machine Learning I - Tarefa: Naufrágio do Titanic",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atejap05/pos_data_science_furg/blob/main/disciplinas/Machine_Learning_I/titanic/Furg_ECD_05_Machine_Learning_I_Tarefa_Naufr%C3%A1gio_do_Titanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFC6buFsHqL2"
      },
      "source": [
        "# Curso de Especialização em Ciência de Dados - FURG\n",
        "## Machine Learning I - Tarefa: Naufrágio do Titanic\n",
        "### Prof. Marcelo Malheiros\n",
        "\n",
        "Código adaptado de Aurélien Geron (licença Apache-2.0)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT_Dek3yHqL6"
      },
      "source": [
        "Esta tarefa é para você **observar** e **analisar** este processo de Machine Learning.\n",
        "\n",
        "Adicionalmente, sugere-se que você também experimente com os dados e com os algoritmos, fazendo algumas das modificações indicadas em várias partes deste _notebook_.\n",
        "\n",
        "Note que não é preciso escrever mais código, apenas modificar o código já fornecido.\n",
        "\n",
        "Um questionário _online_ dentro da disciplina no AVA será disponibilizado para coletar sua análise. Este questionário será também uma das tarefas avaliativas desta disciplina."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um1unyItHqL7"
      },
      "source": [
        "# Problema\n",
        "\n",
        "O problema aqui descrito é uma **tarefa de classificação**. Com base nos dados reais dos passageiros do navio RMS Titanic, precisamos ajustar um **modelo de previsão** para ser capaz de prever a chance de uma dada pessoa sobreviver ou não ao naufrágio (ocorrido em 15 de abril de 1912)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5HTrqOTHqL8"
      },
      "source": [
        "# Inicialização\n",
        "\n",
        "Aqui importamos as bibliotecas fundamentais de Python para este _notebook_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIi8lqGuHqL9"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVpO3LeaHqL-"
      },
      "source": [
        "# Conjunto de dados\n",
        "\n",
        "Este _dataset_ já está separado em dois conjuntos, um para **treino** (`titanic_treino.csv`) e outro para **teste** (`titanic_teste.csv`). \n",
        "\n",
        "Os conjuntos de treino e de teste já estão separados. Basta treinar um **modelo** com o conjunto de treino e analisar uma **medida de desempenho** sobre este.\n",
        "\n",
        "Quando esta medida indicar que o modelo tem boa qualidade, então deve-se usar o conjunto de teste para gerar uma nova previsão, comparar esta com o resultado já conhecido para cada passageiro.\n",
        "\n",
        "**Não se esqueça de fazer o upload dos dados para o Colaboratory, antes de rodar a célula a seguir.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kffajNrbHqL_"
      },
      "source": [
        "# leitura dos conjuntos de dados\n",
        "\n",
        "treino = pd.read_csv('titanic_treino.csv')\n",
        "treino.set_index('id', inplace=True)\n",
        "\n",
        "teste = pd.read_csv(\"titanic_teste.csv\")\n",
        "teste.set_index('id', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZk1ls5yHqMA"
      },
      "source": [
        "Cada conjunto de dados foi colocado em um `DataFrame` (da biblioteca Pandas).\n",
        "\n",
        "Vamos visualizar a seguir os primeiro cinco registros da base de treino:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX7NsqL9HqMB"
      },
      "source": [
        "treino.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpu84NlNHqMD"
      },
      "source": [
        "Os dois conjuntos têm a mesma estrutura de atributos, onde cada linha representa um passageiro. As colunas são os atributos, definidos da seguinte forma:\n",
        "\n",
        "- **id**: um número sequencial, único para cada passageiro\n",
        "\n",
        "- **sobrevivente**: indica se o passageiro sobreviveu (1) ou não (0) ao naufrágio\n",
        "\n",
        "- **classe**: qual a classe da passagem comprada, da primeira (1) até a terceira (3) classe\n",
        "\n",
        "- **nome**: nome completo do passageiro (incluindo apelido, se for o caso)\n",
        "\n",
        "- **sexo**: sexo masculino (M) ou feminino (F)\n",
        "\n",
        "- **idade**: idade em anos\n",
        "\n",
        "- **familia1**: número de cônjuges, de irmãos e de irmãs presentes no navio\n",
        "\n",
        "- **familia2**: número de pais e de filhos do passageiro, também presentes no navio\n",
        "\n",
        "- **tiquete**: código do tíquete de embarque\n",
        "\n",
        "- **tarifa**: preço pago pela passagem, em libras esterlinas\n",
        "\n",
        "- **cabine**: código da cabine do passageiro\n",
        "\n",
        "- **embarque**: porto de embarque do passageiro, sendo Cherbourg (C), Queenstown (Q) ou  Southampton (S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JgmYl2iHqME"
      },
      "source": [
        "# Análise dos dados\n",
        "\n",
        "Aqui vamos computar algumas estatísticas sobre a base original de dados. Estas estatísticas são importantes tanto para perceber quais operações de preprocessamento serão necessárias como para escolher quais _features_ vamos usar no treinamento.\n",
        "\n",
        "Uma função muito útil para isso é a `.info()`, que mostra o tipo de dados e o número de valores presentes em cada coluna:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMEuFUm8HqMF"
      },
      "source": [
        "treino.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXr6MbXVHqMG"
      },
      "source": [
        "Para o conjunto de treino há um total de 891 registros.\n",
        "\n",
        "É possível perceber que há valores faltantes nas colunas `idade`, `cabine` e `embarque`. Na etapa de preprocessamento precisamos completar estes valores (por exemplo, preenchendo as idades faltantes com a mediana de todas as idades). Ou pode-se simplesmente descartar algumas colunas, como faremos depois com `cabine`.\n",
        "\n",
        "Podemos também olhar estatísticas sobre os valores das colunas numéricas usando `.describe()':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BO6-AcbHqMG"
      },
      "source": [
        "treino.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CxBLrUIHqMH"
      },
      "source": [
        "Vale a pena também analisar as colunas que contém poucos valores, chamadas de categóricas, para identificar as classes presentes. Faremos isso chamando a função `.value_counts()` em cada uma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qm4aPEeZHqMH"
      },
      "source": [
        "treino['sobrevivente'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2VMsds_HqMI"
      },
      "source": [
        "treino['classe'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdm4_txiHqMI"
      },
      "source": [
        "treino['sexo'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qab8aN62HqMJ"
      },
      "source": [
        "treino['embarque'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQtHYgwZHqMJ"
      },
      "source": [
        "Como o atributo que desejamos prever, `sobrevivente` só tem dois valores, temos uma tarefa de **classificação binária**. Isso afeta diretamente quais algoritmos podemos usar para fazer o treino, posteriormente.\n",
        "\n",
        "Além disso, de 891 passageiros do conjunto de treino apenas 342 sobreviveram, o que equivale a 38%. O uso da **acurácia** como medida de desempenho parece adequado neste caso, uma vez que não há uma grande disparidade na quantidade de valores 0 e de valores 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-223Q-ufHqMK"
      },
      "source": [
        "# Correlação entre atributos\n",
        "\n",
        "Apenas para gerar uma intuição sobre os dados, vamos visualizar a correlação entre os atributos do conjunto de treino.\n",
        "\n",
        "Para isso usamos a função `.corr()` para calcular o coeficiente de correlação (também chamado de R de Pearson) entre cada par de atributos de um DataFrame.\n",
        "\n",
        "Então visualizamos a correlação com o nosso atributo alvo, `sobrevivente`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnWlLNdFHqMK"
      },
      "source": [
        "# cálculo da matriz de correlação\n",
        "corr = treino.corr()\n",
        "\n",
        "# quanto cada atributo se correlaciona com o valor de 'sobrevivente'\n",
        "corr['sobrevivente']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW5-IA2iHqML"
      },
      "source": [
        "Note que é possível visualizar a tabela inteira, que cruza cada os atributos com todos os demais, como visualizado abaixo. A escala de cores é de um azul mais intenso para valores negativos (no mínimo -1) e de vermelhos mais intensos para valores positivos (no máximo 1). Valores próximos ao zero são também mais próximos do branco.\n",
        "\n",
        "Ainda que haja correlação forte entre alguns atributos, para esta análise só interessam correlações envolvendo o atributo `sobrevivente`, ou seja, da linha superior ou da coluna mais à esquerda da tabela."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COLP5eG5HqML"
      },
      "source": [
        "corr.style.background_gradient(axis=None, cmap='bwr').set_precision(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7yVZPJPHqML"
      },
      "source": [
        "# Separação dos dados\n",
        "\n",
        "Agora vamos separar cada conjunto de dados em duas partes: `features`, que são os atributos sobre os quais treinaremos o modelo, e `rotulos`, que contém o atributo a ser previsto (no caso, apenas `sobrevivente`).\n",
        "        \n",
        "Para simplificar, vamos ignorar os atributos `nome`, `tiquete` e `cabine`, que são meramente textuais."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxPKrQ2UHqMM"
      },
      "source": [
        "# separacão das features\n",
        "treino_features = treino[['classe', 'sexo', 'idade', 'familia1', 'familia2', 'tarifa', 'embarque']]\n",
        "teste_features  =  teste[['classe', 'sexo', 'idade', 'familia1', 'familia2', 'tarifa', 'embarque']]\n",
        "\n",
        "# separação dos rótulos\n",
        "treino_rotulos = treino[['sobrevivente']]\n",
        "teste_rotulos  =  teste[['sobrevivente']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GIdQGTIHqMM"
      },
      "source": [
        "Vamos ver o número de linhas e de colunas de cada subconjunto criado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edgzV-hxHqMN"
      },
      "source": [
        "print('treino_features:', treino_features.shape)\n",
        "print('treino_rotulos: ', treino_rotulos.shape)\n",
        "print('teste_features: ', teste_features.shape)\n",
        "print('teste_rotulos:  ', teste_rotulos.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3AKdGlWHqMN"
      },
      "source": [
        "# Preprocessamento\n",
        "\n",
        "Aqui faremos a etapa de preprocessamento, necessária para transformar os dados brutos em valores mais adequados para os algoritmos de Machine Learning.\n",
        "\n",
        "Lembrando, todo o processo de transformação dos dados é chamado de _pipeline_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCDf9ujbHqMN"
      },
      "source": [
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xozttE8tHqMO"
      },
      "source": [
        "# aqui definimos uma etapa auxiliar do pipeline para atributos categóricos:\n",
        "# esta substitui valores faltando pelo mais frequente de cada coluna\n",
        "# (não se preocupe com os detalhes do código)\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X], index=X.columns)\n",
        "        return self\n",
        "    def transform(self, X, y=None):\n",
        "        return X.fillna(self.most_frequent_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFxkRxWpHqMO"
      },
      "source": [
        "Atributos numéricos (contínuos) e atributos categóricos (discretos) precisam ser processados separadamente.\n",
        "\n",
        "O trecho a seguir define um _pipeline_ genérico, apenas para os atributos numéricos. A etapa usando `SimpleImputer(strategy='median')` preenche valores faltando com a mediana dos valores daquele atributo.\n",
        "\n",
        "**Ajuste:** A etapa de escalonamento usando `StandardScaler()` está desativada. Depois de medir o desempenho do modelo você pode ativar esta etapa, rodando novamente o preprocessamento e o treino, para verificar se melhora a qualidade do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqrZMAMaHqMO"
      },
      "source": [
        "# pipeline para atributos numéricos\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    #('std_scaler', StandardScaler()),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C__czxSGHqMP"
      },
      "source": [
        "O trecho a seguir define um pipeline genérico, apenas para os atributos categóricos.\n",
        "\n",
        "A etapa usando `MostFrequentImputer()` preenche valores faltando com o mais frequente dos valores daquele atributo. Já a etapa seguinte, usando `OneHotEncoder(sparse=False)` expande cada atributo que não é numérico (`classe`, `sexo` ou `embarque`) para um conjunto de atributos binários. Esta precisa ser a última etapa desse _pipeline_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b19ItpYRHqMP"
      },
      "source": [
        "# pipeline para atributos categóricos\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline([\n",
        "    ('imputer', MostFrequentImputer()),\n",
        "    ('encoder', OneHotEncoder(sparse=False)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEK1AeqQHqMP"
      },
      "source": [
        "A seguir usamos o recurso `ColumnTransformer`, muito útil, para aplicar determinados _pipelines_ para apenas alguns atributos dos dados. Assim temos um _pipeline_ inteligente que processa os dados de uma só vez, mas executa operações diferentes conforme a natureza de cada atributo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6vWwNc6HqMQ"
      },
      "source": [
        "# pipeline combinando atributos numéricos com atributos categóricos\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "    ('num', num_pipeline, ['idade', 'familia1', 'familia2', 'tarifa']),\n",
        "    ('cat', cat_pipeline, ['classe', 'sexo', 'embarque']),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrP6Ek37HqMQ"
      },
      "source": [
        "Enfim, processamos os features de treino, gerando um novo conjunto de dados pronto para o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_TB8ZmeHqMQ"
      },
      "source": [
        "X_treino = full_pipeline.fit_transform(treino_features)\n",
        "print('X_treino:', X_treino.shape)\n",
        "print(X_treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhJcQK8HHqMR"
      },
      "source": [
        "Aqui vamos extrair somente os dados brutos dos rótulos, e colocar em `y_treino`, que é o formato esperado pelos algoritmos de Machine Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXYFoBNnHqMR"
      },
      "source": [
        "y_treino = treino_rotulos.values.ravel()\n",
        "print('y_treino:', y_treino.shape)\n",
        "#print(y_treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycJvMubDHqMS"
      },
      "source": [
        "# Seleção do modelo\n",
        "\n",
        "Aqui selecionamos um modelo para o aprendizado, baseado em um dos possíveis algoritmos de classificação binária. \n",
        "\n",
        "**Ajuste:** Depois de medir o desempenho do modelo você pode habilitar outros algoritmos. Note que apenas um par de comandos deve estar ativo (a linha `from` e a correspondente criação do `classificador`).\n",
        "\n",
        "- Para o algoritmo `SVC` você pode mudar o parâmetro para `gamma='auto'`.\n",
        "\n",
        "- Para o algoritmo `SGDClassifier` você pode mudar o parâmetro para `loss='log'`.\n",
        "\n",
        "- Para o algoritmo `LogisticRegression` você **precisa ter os dados escalonados** como parte do _pipeline_ numérico. Ou seja, é preciso que a linha do `StandardScaler()` esteja habilitada e que os dados sejam novamente preprocessados.\n",
        "\n",
        "- Para o algoritmo `RandomForestClassifier` você pode aumentar o parâmetro `n_estimators`, por exemplo para 10 ou 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUUkca4BHqMS"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "classificador = SVC(random_state=42, gamma='scale')\n",
        "\n",
        "#from sklearn.linear_model import SGDClassifier\n",
        "#classificador = SGDClassifier(random_state=42, loss='hinge')\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "#classificador = LogisticRegression(random_state=42)\n",
        "\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "#classificador = RandomForestClassifier(random_state=42, n_estimators=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsfXqIBHqMS"
      },
      "source": [
        "# Treino e medida de desempenho\n",
        "\n",
        "Vamos treinar e avaliar um classificador fazendo a **validação cruzada** do conjunto de treino. O parâmetro `cv` indica o número de dobras (ou _folds_), que é o número de vezes em que o conjunto é repartido, treinado e mensurado.\n",
        "\n",
        "Como medida de desempenho vamos usar a **acurácia** (_accuracy_), que indica o percentual de acertos na previsão.\n",
        "\n",
        "Como a validação cruzada devolve várias medidas, guardadas na lista `scores`, calculamos e exibimos uma média aritmética simples dessas medidas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFpMf_7zHqMS"
      },
      "source": [
        "# validação cruzada\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(classificador, X_treino, y_treino, cv=10, scoring='accuracy')\n",
        "print('{:.2%}'.format(scores.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLFEsXWZHqMT"
      },
      "source": [
        "**Opcional:** Para melhorar o modelo existem diversas possibilidades de **ajuste** do modelo:\n",
        "\n",
        "- A ação mais direta é simplesmente testar outros algoritmos, como mostrado na seção \"Seleção do Modelo\".\n",
        "\n",
        "- Você também pode ativar o escalonamento de _features_ na seção \"Preprocessamento\" e ver se houve ganho.\n",
        "\n",
        "- Outra possibilidade é reduzir o número de _features_, simplesmente retirando atributos numéricos e categóricos do _pipeline_ `full_pipeline` na seção \"Preprocessamento\".\n",
        "\n",
        "**Avançado**: Ainda é possível criar novas _features_ (o que precisa ser feito na seção \"Separação dos dados\"). Seguem três sugestões (que precisariam ser repetidas para o conjunto `teste`):\n",
        "\n",
        "    # novo atributo (categórico) agrupando idades por faixas\n",
        "    treino['faixa_etaria'] = treino['idade'] // 15 * 15\n",
        "    treino[['faixa_etaria', 'sobrevivente']].groupby(['faixa_etaria']).mean()    \n",
        "\n",
        "    # novo atributo (numérico ou categórico), agrupando dados sobre familiares\n",
        "    treino['total_parentes'] = treino['familia1'] + treino['familia2']\n",
        "    treino[['total_parentes', 'sobrevivente']].groupby(['total_parentes']).mean()\n",
        "\n",
        "    # novo atributo (binário e categórico) identificando passageiros viajando sozinhos\n",
        "    # (apenas 30% destes sobreviveram)\n",
        "    treino['sozinho'] = (treino['familia1'] + treino['familia2']) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oCAmyKjHqMT"
      },
      "source": [
        "# Teste final do modelo\n",
        "\n",
        "Se você estiver satisfeito com a qualidade do modelo obtido (com base apenas nos rótulos de treino), então podemos fazer o teste final do modelo.\n",
        "\n",
        "Vamos gerar a versão treinada do modelo, preprocessar os dados de teste e então gerar previsões.\n",
        "\n",
        "Note que o treinamento do modelo é feito de fato aqui, com a chamada de `.fit()`. A validação cruzada feita anteriormente gera modelos temporários para as medidas e os descarta, mas não deixa o modelo treinado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9yIkQW5HqMU"
      },
      "source": [
        "# treinamento\n",
        "classificador.fit(X_treino, y_treino)\n",
        "\n",
        "# preprocessamento dos dados de teste\n",
        "X_teste = full_pipeline.transform(teste_features)\n",
        "\n",
        "# geração das previsões\n",
        "y_teste_pred = classificador.predict(X_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SM7sIViHqMU"
      },
      "source": [
        "Agora vamos avaliar a acurácia novamente, porém comparando o valores previstos com base nos dados de teste contra os rótulos reais para os mesmos dados de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-omXxZ8HqMU"
      },
      "source": [
        "# rótulos reais\n",
        "y_teste = teste_rotulos.values.ravel()\n",
        "\n",
        "# medida de acurácia\n",
        "from sklearn.metrics import accuracy_score\n",
        "score = accuracy_score(y_teste, y_teste_pred)\n",
        "print('{:.2%}'.format(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHSn1HNcHqMW"
      },
      "source": [
        "# Gerando novas previsões\n",
        "\n",
        "Uma vez treinado e testado, o modelo pode ser usado para gerar previsões sobre dados nunca antes vistos.\n",
        "\n",
        "No exemplo abaixo um `DataFrame` com o mesmo formato dos conjuntos de `features` é criado, com apenas uma linha. Para essa pessoa fictícia, podemos usar o modelo para gerar uma previsão de sua possível sobrevivência ou não ao naufrágio do Titanic:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UWss_jNHqMW"
      },
      "source": [
        "anon = pd.DataFrame(columns=['classe', 'sexo', 'idade', 'familia1', 'familia2', 'tarifa', 'embarque'],\n",
        "                    data   =[[      2,    'M',     40,           1,          0,     50.0,        'Q']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq48A8rCHqMW"
      },
      "source": [
        "X_anon = full_pipeline.transform(anon)\n",
        "y_anon = classificador.predict(X_anon)\n",
        "y_anon[0]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}